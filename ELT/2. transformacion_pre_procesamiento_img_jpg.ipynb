{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9a5ea3",
   "metadata": {},
   "source": [
    "<img src=\"https://www.unir.net/wp-content/uploads/2019/11/Unir_2021_logo.svg\" width=\"240\" height=\"240\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780e5cd",
   "metadata": {},
   "source": [
    "<span>\n",
    "<h2>Eliminación de ruido en imagenes de resonancia magnetica, mediante red neuronal convolucional CNN </h2> \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35422d",
   "metadata": {},
   "source": [
    "Procedimiento de entrenamiento con imagenes en formato cerebrales, extraidas previamente de imagenes en formato .NIFTI a JPG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a692ff",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c0b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from scipy import ndimage, misc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b003b",
   "metadata": {},
   "source": [
    "## Carga y lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2949b6",
   "metadata": {},
   "source": [
    "Se cargarán las imagenes en formato JPG almacenadas en el directorio local\n",
    "el cual se creo en el Notebook previo 1. Extraccion_Imagenes_Nifti_A_Jpg. Dichas imagenes serán almacenadas en los siguientes conjuntos <b>datos entrenamiento, validación y prueba.</b>\n",
    "\n",
    "Los datos utilizados en este proyecto fuerón dispuestos por el archivo de imágenes y datos <a href=\"https://adni.loni.usc.edu/data-samples/access-data/\">(IDA)</a> está a cargo del Laboratorio de neuroimagen (LONI) en el Instituto de informática y neuroimagen Mark and Mary Stevens de la USC. Del cual se descargaron 2294 imagenes en formato .nii de 639 pacientes, con un periodo de 3 años de tomas de IMR para el Alzheimer, en personas entre los 55 y 91 años de edad. Dichas imagenes se convirtieron en imagenes en formato .jpg, duplicando la cantidad de las mismas, ya que por cada imagen 3D se extajo la dimension del corte axial y corte coronal, las cuales brindan información valioda para la detección de la enfermedad del Alzheimer, ignorando asi el corte sagital y obteniendo una totalidad de 4588 imagenes en formato JPG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb65a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Categorizacion datos de entrenamiento, validación y prueba\n",
    "\n",
    "1. Imagenes disponibles en jpg (Corte Axial y Coronal)\n",
    "\n",
    "clasificacion  cantidad\n",
    "AD             952\n",
    "CN             1410\n",
    "MCI            2226\n",
    "-----------------------\n",
    "TOTAL          4588\n",
    "\n",
    "2. División por cada conjunto de datos\n",
    "\n",
    "clasificacion  cantidad  entrenamiento (80%)  validacion (19%)  prueba (1%)\n",
    "AD             952       762                  181               9\n",
    "CN             1410      1128                 268               14\n",
    "MCI            2226      1781                 423               22\n",
    "---------------------------------------------------------------------------\n",
    "TOTAL          4588      3671                 872               45\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_conjuntos = pd.DataFrame(columns=['clasificacion', 'cantidad' ,'entrenamiento','validacion', 'prueba'])\n",
    "df_conjuntos.loc[1] = ['AD', 952, 762, 181, 9]  \n",
    "df_conjuntos.loc[2] = ['CN', 1410, 1128, 268, 14]\n",
    "df_conjuntos.loc[3] = ['MCI', 2226, 1781, 423, 22]\n",
    "df_conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Helpers/sqllite_helper.ipynb\n",
    "helper_sqllite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e6756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database = r\"C:\\sqllite\\alzheimer_db.db\"\n",
    "conn = create_connection(database)\n",
    "\n",
    "query = \"SELECT * FROM log_metadatos_consolidado\"\n",
    "df_adni = query_table(conn, query)\n",
    "df_adni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b56c11",
   "metadata": {},
   "source": [
    "<b>Asignacion de grupos de datos</b>\n",
    "\n",
    "Clasificacion de conjuntos de datos Entrenamiento, validacion y prueba. Adicional se crean 3 columnas calculadas para almacenar los valores de los directorios donde se clasificaran las imagenes en los sub conjuntos de datos mensionados previamente con el fin de pre procesar las imagenes y por ultimo utilizarlas para contruir el modelo de deteccion de la enfermedad de alzheimer, mediante varias arquitecturas de redes neuronales CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe = pd.DataFrame()\n",
    "df_conj_iter = df_conjuntos.iterrows()\n",
    "for index, row in df_conj_iter:\n",
    "    print(row['clasificacion'], \n",
    "          row['entrenamiento'],\n",
    "          row['validacion'], \n",
    "          row['prueba'])\n",
    "    \n",
    "    df_actual = df_adni[df_adni['group_m']==row['clasificacion']]\n",
    "    df_actual = df_actual.reset_index(level=0)\n",
    "    df_actual['index1'] = df_actual.index\n",
    "    \n",
    "    min_idx_entrenaiento = min(df_actual['index'])\n",
    "    max_idx_entrenamiento = min_idx_entrenaiento + row['entrenamiento']\n",
    "\n",
    "    min_idx_validacion = max_idx_entrenamiento\n",
    "    max_idx_validacion = min_idx_validacion + row['validacion']\n",
    "\n",
    "    min_idx_prueba = max_idx_validacion\n",
    "    max_idx_prueba = min_idx_prueba + row['prueba']\n",
    "    \n",
    "    tipo_conjunto_1 = 'ENTRENAMIENTO'\n",
    "    tipo_conjunto_2 = 'VALIDACION'\n",
    "    tipo_conjunto_3 = 'PRUEBA'    \n",
    "    \n",
    "    cond_idx_entrenamiento = ((df_actual.index1 >=  min_idx_entrenaiento) & (df_actual.index1 <  max_idx_entrenamiento))\n",
    "    cond_idx_validacion = ((df_actual.index1 >=  min_idx_validacion)   & (df_actual.index1 <  max_idx_validacion))\n",
    "    cond_idx_prueba = ((df_actual.index1 >=  min_idx_prueba)       & (df_actual.index1 <  max_idx_prueba))\n",
    "\n",
    "    # agregar tipo de conjunto para las imagenes.\n",
    "    df_actual['tipo_conjunto'] = np.select(\n",
    "    [\n",
    "        cond_idx_entrenamiento,\n",
    "        cond_idx_validacion,\n",
    "        cond_idx_prueba\n",
    "    ], \n",
    "    [\n",
    "       tipo_conjunto_1,\n",
    "       tipo_conjunto_2,\n",
    "       tipo_conjunto_3\n",
    "    ], \n",
    "    default='_sin_conjunto' )\n",
    "    \n",
    "    # agregar ruta de almacenamiento para conjunto de datos de entrenamiento, validacion y pruebas\n",
    "    root_path_conjunto_pre_proc = 'D:\\ADNI - IDA\\ADNI1_Complete 1Yr 1.5T\\ADNI-PRE-PROCESAMIENTO'\n",
    "    df_actual['path_conjunto_pre_procesamiento'] = np.select(\n",
    "    [\n",
    "        cond_idx_entrenamiento,\n",
    "        cond_idx_validacion,\n",
    "        cond_idx_prueba\n",
    "    ], \n",
    "    [\n",
    "        root_path_conjunto_pre_proc + '\\\\' + tipo_conjunto_1 + '\\\\PROCESADO\\\\',\n",
    "        root_path_conjunto_pre_proc + '\\\\' + tipo_conjunto_2 + '\\\\PROCESADO\\\\',\n",
    "        root_path_conjunto_pre_proc + '\\\\' + tipo_conjunto_3 + '\\\\PROCESADO\\\\'\n",
    "    ], \n",
    "    default='_sin_conjunto')\n",
    "    \n",
    "    # agregar ruta de almacenamiento para conjunto de datos de entrenamiento, validacion y pruebas\n",
    "    root_path_conjunto_deteccion = 'D:\\ADNI - IDA\\ADNI1_Complete 1Yr 1.5T\\ADNI-PRE-PROCESAMIENTO'\n",
    "    df_actual['path_conjunto_deteccion'] = np.select(\n",
    "    [\n",
    "        cond_idx_entrenamiento,\n",
    "        cond_idx_validacion,\n",
    "        cond_idx_prueba\n",
    "    ], \n",
    "    [\n",
    "        root_path_conjunto_deteccion + '\\\\' + tipo_conjunto_1 + '\\\\' + row['clasificacion'] + '\\\\',\n",
    "        root_path_conjunto_deteccion + '\\\\' + tipo_conjunto_2 + '\\\\' + row['clasificacion'] + '\\\\',\n",
    "        root_path_conjunto_deteccion + '\\\\' + tipo_conjunto_3 + '\\\\' + row['clasificacion'] + '\\\\'        \n",
    "    ], \n",
    "    default='_sin_conjunto')\n",
    "    \n",
    "    # df_actual =  df_actual.rename(columns={\"image_data_id\": \"image_data_id_x\", \"subject\": \"subject_x\"})   \n",
    "    result_dataframe = result_dataframe.append(df_actual, ignore_index=True)\n",
    "\n",
    "result_dataframe.drop(['index', 'level_0', 'index1'], axis = 1, inplace = True) \n",
    "print(result_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe.sort_values(by=[\"orden\"], ascending=False, inplace = True)\n",
    "result_dataframe.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b3617",
   "metadata": {},
   "source": [
    "## Carga datos de pre procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "209e480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in result_dataframe.iterrows():\n",
    "    \n",
    "#     print(row['tipo_conjunto'])\n",
    "#     print(row['path_jpg'])\n",
    "#     print(row['path_conjunto_pre_procesamiento'])\n",
    "#     print(row['path_conjunto_deteccion'])\n",
    "#     print(row['file_name_jpg'], '\\n')\n",
    "    \n",
    "    original = row['path_jpg']  + '\\\\' + row['file_name_jpg'] + '.jpg'\n",
    "    target_path   = row['path_conjunto_pre_procesamiento'] \n",
    "    target   = row['path_conjunto_pre_procesamiento'] + row['file_name_jpg'] + '.jpg'\n",
    "    \n",
    "#     print(original, '\\n')\n",
    "#     print(target, '\\n')\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(target_path):\n",
    "            os.makedirs(target_path)\n",
    "    \n",
    "        os.chmod(target_path, 0o777)\n",
    "        shutil.copyfile(original, target)\n",
    "    except:\n",
    "        print(\"Error copiando: \", original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5f37c",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2112135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de iteraciones para los datos de entrenamiento\n",
    "epochs = 15 \n",
    "\n",
    "# Número de parches de imágenes usados para calcular un solo\n",
    "batch_size = 32        \n",
    "\n",
    "# Tasa de aprendizaje\n",
    "learning_rate = 0.0001  \n",
    "\n",
    "# Funcion de optimizacion para los parametros mediante la tasa o gradiente \n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "# metricas de monitoreo\n",
    "progress_example = 2\n",
    "buffer = 128\n",
    "progress_ims = []\n",
    "\n",
    "\n",
    "def train(loss_function, model):\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "    # As the training progresses, we'll monitor network output and performance\n",
    "    # metrics. Some related variables are initialized here\n",
    "    example_input = test_input[[3], ...]\n",
    "    edge_buffer = 128\n",
    "    progress_ims = []\n",
    "    progress_val = []\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "        \n",
    "        # Evaluate model on reserved data\n",
    "        val_loss = model.evaluate(val_input, val_target)\n",
    "        example_output = model.predict(example_input)\n",
    "        example_img = example_output[0, edge_buffer:-edge_buffer,\n",
    "                                  edge_buffer:-edge_buffer, 0]\n",
    "        progress_ims.append(example_img)\n",
    "        progress_val.append(val_loss)\n",
    "        # Update model weights using training data\n",
    "        istart = 0\n",
    "        while istart < (len(train_input) - batch_size):\n",
    "            x = train_input[istart:istart + batch_size]\n",
    "            y = train_target[istart:istart + batch_size]\n",
    "            model.train_on_batch(x=x, y=y)\n",
    "            istart += batch_size\n",
    "\n",
    "    progress_ims = np.stack(progress_ims, axis=0)\n",
    "\n",
    "    print('Training phase complete.')\n",
    "    return model, progress_ims, progress_val\n",
    "\n",
    "\n",
    "# Now run the training fuction to obtain the trained model and performance at\n",
    "# intermediate steps\n",
    "denoising_model, progress_ims, progress_val = train(loss_function='mse', model=denoising_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33712210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941f7aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd921db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c262954e",
   "metadata": {},
   "source": [
    "https://pubs.rsna.org/doi/full/10.1148/ryai.2020200036\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
